{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d91286-3d14-4fa1-9ee5-191eb75b4964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "\n",
    "# Pre-Processing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GRU, Conv1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Fine-Tuning and Tracking\n",
    "import wandb\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, matthews_corrcoef\n",
    "\n",
    "# Hide Debug Info\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303bef0-d59f-4afb-a357-b1107f27e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../Data/Processed/processed_binary.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6c838-595c-46c5-905d-efd36a40df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Weights and Bias\n",
    "wandb.init(project=\"misinformation_nlp\")\n",
    "\n",
    "config = dict(\n",
    "    model='BiLSTM+DENSE',\n",
    "    embedding_dim = 200,\n",
    "    num_words = 20000,\n",
    "    learning_rate = 0.0001,\n",
    "    units = 52,\n",
    "    input_len = 56,\n",
    "    trainable = False,\n",
    "    dropout = 0.5,\n",
    "    batch_size = 256,\n",
    "    epochs = 20,\n",
    "    shuffle = True\n",
    ")\n",
    "wandb.config.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05873e-d114-4571-b371-c112c493edd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "glove_file = '../Embeddings/glove.twitter.27B.' + str(wandb.config.embedding_dim) + 'd.txt'\n",
    "embeddings_index = load_glove_embeddings(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1245ba-f444-48d3-8ead-c2eeb1685a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['tweet'].astype(str)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=wandb.config.num_words, oov_token=\"<pad>\", lower=False) \n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df3536-79c8-436e-9aeb-70df32e10db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, padding='post', maxlen=wandb.config.input_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426f935-490b-4986-87a4-6662ddcf3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, wandb.config.embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554e031-4e14-4894-8908-84c11f380307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=vocab_size, output_dim=wandb.config.embedding_dim, input_length=wandb.config.input_len, trainable=wandb.config.trainable))\n",
    "# model.add(LSTM(units=wandb.config.units))\n",
    "# model.add(Dropout(wandb.config.dropout))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# optimiser = Adam(learning_rate=wandb.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887dae6c-b07f-4e7e-90be-07ddcbaa54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=vocab_size, output_dim=wandb.config.embedding_dim, input_length=wandb.config.input_len, trainable=wandb.config.trainable))\n",
    "# model.add(Bidirectional(LSTM(units=wandb.config.units)))\n",
    "# model.add(Dropout(wandb.config.dropout))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# optimiser = Adam(learning_rate=wandb.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1ca67-6b80-442e-8c79-db3c8172abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=vocab_size, output_dim=wandb.config.embedding_dim, input_length=wandb.config.input_len, trainable=wandb.config.trainable))\n",
    "# model.add(GRU(units=wandb.config.units))\n",
    "# model.add(Dropout(wandb.config.dropout))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# optimiser = Adam(learning_rate=wandb.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbda30-027c-4df0-9e1c-79c345af9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=vocab_size, output_dim=wandb.config.embedding_dim, input_length=wandb.config.input_len, trainable=wandb.config.trainable))\n",
    "# model.add(Bidirectional(GRU(units=wandb.config.units)))\n",
    "# model.add(Dropout(wandb.config.dropout))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# optimiser = Adam(learning_rate=wandb.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472f191-b3c3-4569-a2c6-99d7153ddf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Embedding, Conv1D, LSTM, Bidirectional, Dropout, Dense\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=vocab_size, output_dim=wandb.config.embedding_dim, input_length=wandb.config.input_len, trainable=wandb.config.trainable))\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "# model.add(LSTM(units=wandb.config.units))\n",
    "# model.add(Dropout(wandb.config.dropout))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# optimiser = Adam(learning_rate=wandb.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81113c8-92f3-41ea-b115-787fa557525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    " \n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
    "                               initializer='zeros', trainable=True)        \n",
    "        super(attention, self).build(input_shape)\n",
    " \n",
    "    def call(self,x):\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)   \n",
    "        # Compute the weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfffaee-cfca-4225-9789-ab0affa0ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=wandb.config.embedding_dim, input_length=wandb.config.input_len, trainable=wandb.config.trainable))\n",
    "model.add(Bidirectional(LSTM(units=wandb.config.units)))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(wandb.config.dropout))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimiser = Adam(learning_rate=wandb.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b9252-a3bf-44ae-9d81-46d007e9d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7782166-1f14-41f6-8176-9e36f9a57a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, df['target_binary'], test_size=0.25, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66881431-f7f2-4bd0-8971-abc3e4e34bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,           \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "history = model.fit(X_train, y_train, batch_size=wandb.config.batch_size, epochs=wandb.config.epochs, validation_split=0.15, shuffle=wandb.config.shuffle, callbacks=[early_stopping, wandb.keras.WandbCallback()])\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "training_time = (end_time - start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067795a-218d-4160-8e53-ddd9aeb49882",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = model.predict(X_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252df24-3bef-4fb7-83b9-30f71d9b985e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_preds_binary = (predictions_train > 0.5).astype(int)\n",
    "train_acc = accuracy_score(y_train, train_preds_binary)\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4287c0a-7c5c-467f-8271-87a4fa78bb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds_binary = (predictions > 0.5).astype(int)\n",
    "test_acc = accuracy_score(y_test, test_preds_binary)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e1e29-4df3-4fb0-b25d-ae53308fc1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, predictions)\n",
    "mcc = matthews_corrcoef(y_test, test_preds_binary)\n",
    "\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"MCC:\", mcc)\n",
    "print(\" --- CLASSIFICATION REPORT --- \" )\n",
    "print(classification_report(y_test, test_preds_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8001904-adfd-4f4e-bafb-f00043d86d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_val_df = pd.read_json('../Data/Processed/processed_binary_val.json')\n",
    "external_val_df = pd.read_json('../Data/Cross_Validation/COVID_processed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7442d-6c0b-4ba2-83b2-02f95491acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_val_texts = internal_val_df['tweet'].astype(str)\n",
    "e_val_texts = external_val_df['tweet'].astype(str)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=wandb.config.num_words, oov_token=\"<pad>\") \n",
    "\n",
    "tokenizer.fit_on_texts(i_val_texts)\n",
    "tokenizer.fit_on_texts(e_val_texts)\n",
    "\n",
    "i_val_sequences = tokenizer.texts_to_sequences(i_val_texts)\n",
    "e_val_sequences = tokenizer.texts_to_sequences(e_val_texts)\n",
    "\n",
    "i_val_padded = pad_sequences(i_val_sequences, maxlen=wandb.config.input_len) \n",
    "e_val_padded = pad_sequences(e_val_sequences, maxlen=wandb.config.input_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc2a8c-5921-45a1-acd7-3e7ef5269cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i_val_predictions = model.predict(i_val_padded)\n",
    "e_val_predictions = model.predict(e_val_padded)\n",
    "\n",
    "# Convert probabilities to binary\n",
    "i_val_predictions_binary = (i_val_predictions > 0.5).astype(int)\n",
    "e_val_predictions_binary = (e_val_predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcabad00-d5d6-4a51-a56c-d6cd2d4ab8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_val_mcc = matthews_corrcoef(internal_val_df['target_binary'], i_val_predictions_binary)\n",
    "i_val_acc = accuracy_score(internal_val_df['target_binary'], i_val_predictions_binary)\n",
    "print(f\"(I) Validation: Matthews Correlation Coefficient: {i_val_mcc}\")\n",
    "print(f\"(I) Validation: Accuracy: {i_val_acc}\")\n",
    "print(\"---\")\n",
    "e_val_mcc = matthews_corrcoef(external_val_df['target'], e_val_predictions_binary)\n",
    "e_val_acc = accuracy_score(external_val_df['target'], e_val_predictions_binary)\n",
    "print(f\"(I) Validation: Matthews Correlation Coefficient: {e_val_mcc}\")\n",
    "print(f\"(E) Validation Accuracy: {e_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ffd1c-3831-4acb-bfef-f5fbc020db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_val_mcc = i_val_mcc + e_val_mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc3e49-0f2b-401f-869f-a8ff0c9cd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'Train Accuracy': train_acc, 'Test Accuracy': test_acc, 'AUC': auc, 'MCC': mcc, 'Training Time': training_time, '(Internal) Validation MCC': i_val_mcc, '(Internal) Validation ACC': i_val_acc, '(External) Validation MCC': e_val_mcc, '(External) Validation Accuracy': e_val_acc, 'Total Validation MCC': total_val_mcc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cc47d-b20b-404b-805c-5097e91c50a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a6126c-dc07-434d-be13-5b8eddaf1ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
