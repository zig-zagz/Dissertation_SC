{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ad550-b045-4633-b489-68c437d78885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbac176-dae7-4fc1-be5f-6fe93beaee2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/Truth_Seeker_Model_Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275bed3-66af-4f35-b4c2-15e5fbf2f01a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10978da1-3482-4d00-8811-2cbb1dda88f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['3_label_majority_answer'].unique())\n",
    "print(df['5_label_majority_answer'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac9dd9-df6a-4f5d-80a2-055beea64daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_source_df = df[df['BinaryNumTarget'] == 1].copy()\n",
    "false_source_df = df[df['BinaryNumTarget'] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a9e01-ec54-436a-8417-2b6a936643e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping_true_binary = {\n",
    "    'Agree': 1,\n",
    "    'Disagree': 0\n",
    "\n",
    "}\n",
    "\n",
    "label_mapping_false_binary = {\n",
    "    'Agree': 0,\n",
    "    'Disagree': 1,\n",
    "}\n",
    "\n",
    "true_source_df['target_binary'] = true_source_df['3_label_majority_answer'].replace(label_mapping_true_binary)\n",
    "false_source_df['target_binary'] = false_source_df['3_label_majority_answer'].replace(label_mapping_false_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a8592-1f3e-4252-8d79-a12ee53f1c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping_true_5 = {\n",
    "    'Agree': 'true',\n",
    "    'Mostly Agree': 'mostly_true',\n",
    "    'NO MAJORITY': 'no_majority',\n",
    "    'Mostly Disagree': 'mostly_false',\n",
    "    'Disagree': 'false'\n",
    "}\n",
    "\n",
    "label_mapping_false_5 = {\n",
    "    'Agree': 'false',\n",
    "    'Mostly Agree': 'mostly_false',\n",
    "    'NO MAJORITY': 'no_majority',\n",
    "    'Mostly Disagree': 'mostly_true',\n",
    "    'Disagree': 'true'\n",
    "}\n",
    "\n",
    "true_source_df['target_5'] = true_source_df['5_label_majority_answer'].replace(label_mapping_true_5)\n",
    "false_source_df['target_5'] = false_source_df['5_label_majority_answer'].replace(label_mapping_false_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f047e56-cff5-4297-818e-025f5da342ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([true_source_df, false_source_df], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8371fa4-87c7-4311-8905-d148d6027054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping_3 = {\n",
    "    'true': 'true',\n",
    "    'mostly_true': 'true',\n",
    "    'no_majority': 'no_majority',\n",
    "    'mostly_false': 'false',\n",
    "    'false': 'false'\n",
    "}\n",
    "\n",
    "df['target_3'] = df['target_5'].replace(label_mapping_3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce6d5e-d99b-4d54-8ba4-e4f55be5bc61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['tweet', 'manual_keywords', 'statement', 'target_binary', 'target_3', 'target_5']].copy()\n",
    "df = df.rename(columns={'manual_keywords': 'keywords'}).copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9130e98-b583-4ae3-8738-951eab90973f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "def preprocess_text(text, number_indicator=\"NUM\", url_indicator=\"URL\", percent_indicator=\"PERCENT\", money_indicator=\"MONEY\"):\n",
    "    \n",
    "    punctuation = r\"[\\]^_`{|}&<>*#-:\"\n",
    "\n",
    "    # Function to expand contractions\n",
    "    def replace_contractions(text):\n",
    "        contractions_pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in contraction_dict.keys()) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "        def expand_match(contraction):\n",
    "            match = contraction.group(0)\n",
    "            first_char = match[0]\n",
    "            expanded_contraction = contraction_dict[match.lower() if match.lower() in contraction_dict else match]\n",
    "            return first_char + expanded_contraction[1:] if first_char.isupper() else expanded_contraction\n",
    "\n",
    "        return contractions_pattern.sub(expand_match, text)\n",
    "\n",
    "    # Expand contractions\n",
    "    text = replace_contractions(text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    for p in punctuation:\n",
    "        text = text.replace(p, \"\")\n",
    "\n",
    "    # Replace URLs with URL\n",
    "    url_pattern = r'https?//(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    text = re.sub(url_pattern, url_indicator, text)\n",
    "\n",
    "    # Label MONEY\n",
    "    text = re.sub(r'\\$\\b(?!0+(?:\\.0+)?$)\\d+(\\.\\d{1,2})?\\b', lambda m: money_indicator, text)\n",
    "\n",
    "    # Replace numbers, except years, with NUM \n",
    "    text = re.sub(r'\\b\\d{1,3}\\b', number_indicator, text)\n",
    "    text = re.sub(r'\\b(?!1|2)\\d{4,}\\b', number_indicator, text)\n",
    "    \n",
    "    # Label PERCENT\n",
    "    text = text.replace(number_indicator + \"%\", percent_indicator)\n",
    "    \n",
    "    # Replace newline with a space and remove mentions\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d222cc-5b33-47ef-8c3e-0de094531dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_text = \"I'm sure it'll be great in 2024, but it costs $20. Visit https://example.com or call 123 for details. There's a 100% chance!\"\n",
    "processed_text = preprocess_text(example_text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdc200-896a-4426-8028-ed3fa5834e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df['tweet'] = df['tweet'].apply(lambda x: pd.Series(preprocess_text(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae6e64-8950-4daa-b423-24a8a64b8f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_json('Processed/processed_all.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be66c0c-a1d9-4181-a990-44a1e86ed75e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into individual Keywords\n",
    "df['keywords'] = df['keywords'].str.split(', ')\n",
    "\n",
    "# Explode the Dataframe\n",
    "df_exploded = df.explode('keywords')\n",
    "df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f33769-62e9-4f96-865f-da9f9efb52e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract COVID specific tweets\n",
    "covid_df = df_exploded[df_exploded['keywords'].str.contains('COVID|COVID-19|covid|covid-19|corona|pandemic|virus', case=False, na=False)]\n",
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95e378-3f4d-4f28-8064-5e238fb6d00c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "covid_df['tweet'] = covid_df['tweet'].drop_duplicates()\n",
    "covid_df = covid_df.dropna(subset=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d078c-a223-48f2-a243-fdee7672c8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "covid_df[\"target_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf02810-d9a9-407e-8273-53b4a51db690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop val Tweets from DF\n",
    "df = df.drop(covid_df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f248f0-c91b-4560-89af-ca199208035d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd5cb7-9d86-4a9a-98a4-60a73e51e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset_by_source_statement(df):\n",
    "    # Initialize an empty list to store the balanced dataframes\n",
    "    balanced_dfs = []\n",
    "\n",
    "    # Group by the 'keywords_str' column\n",
    "    grouped = df.groupby('statement')\n",
    "\n",
    "    # Iterate over each group\n",
    "    for name, group in grouped:\n",
    "        false = group[group['target_binary'] == 0]  # Filtering false samples\n",
    "        true = group[group['target_binary'] == 1]   # Filtering true samples\n",
    "        \n",
    "        # Determine the minimum number of samples\n",
    "        minimum = min(len(false), len(true))\n",
    "        \n",
    "        # Concatenate the balanced samples\n",
    "        result = pd.concat([false.head(minimum), true.head(minimum)])\n",
    "    \n",
    "        balanced_dfs.append(result)\n",
    "\n",
    "    # Concatenate all balanced dataframes in the list\n",
    "    balanced_df = pd.concat(balanced_dfs)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = balance_dataset_by_source_statement(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54b010-9f4c-45a6-b0c3-34b7c4ac95ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balanced_df = balanced_df.sort_index()\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf781e0-9197-4297-ba49-e65310203258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Binary\n",
    "df[['tweet', 'target_binary']].to_json('Processed/processed_binary.json', orient='records')\n",
    "covid_df[['tweet', 'target_binary']].to_json('Processed/processed_binary_val.json', orient='records')\n",
    "\n",
    "# Multiclass\n",
    "df[['tweet', 'target_3']].to_json('Processed/processed_multiclass_3.json', orient='records')\n",
    "covid_df[['tweet', 'target_3']].to_json('Processed/processed_multiclass_3_val.json', orient='records')\n",
    "\n",
    "df[['tweet', 'target_5']].to_json('Processed/processed_multiclass_5.json', orient='records')\n",
    "covid_df[['tweet', 'target_5']].to_json('Processed/processed_multiclass_5_val.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
